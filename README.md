# ğŸ¬ AnÃ¡lise de Sentimentos em Reviews de Filmes  
### ClassificaÃ§Ã£o AutomÃ¡tica de Reviews do IMDb com Machine Learning e NLP

---

## ğŸ“Œ VisÃ£o Geral

Este projeto implementa um pipeline **completo e profissional** de *Natural Language Processing (NLP)* para classificar reviews de filmes como **positivos** ou **negativos**.  
O objetivo foi construir um modelo limpo, interpretÃ¡vel e com desempenho competitivo, ideal para compor um portfÃ³lio em CiÃªncia de Dados.

---

## â­ Principais Resultados

- âœ”ï¸ AcurÃ¡cia final: **~89%** (Logistic Regression e SVM)  
- âœ”ï¸ Pipeline completo: EDA â†’ Limpeza â†’ VetorizaÃ§Ã£o â†’ Modelagem â†’ InterpretaÃ§Ã£o  
- âœ”ï¸ TFâ€‘IDF com **10.000 features**  
- âœ”ï¸ ExtraÃ§Ã£o de *features* mais importantes  
- âœ”ï¸ Projeto totalmente replicÃ¡vel

---

---

## ğŸ” 1. EDA â€” AnÃ¡lise ExploratÃ³ria

A anÃ¡lise inicial identificou:

- Dataset balanceado entre reviews positivos e negativos  
- Textos com grande variaÃ§Ã£o de tamanho  
- PresenÃ§a de HTML, tags `<br>`, pontuaÃ§Ã£o e caracteres especiais  
- Necessidade de limpeza profunda antes da vetorizaÃ§Ã£o  

Durante o EDA foram criados grÃ¡ficos como:

- DistribuiÃ§Ã£o dos tamanhos dos textos  
- FrequÃªncia das palavras mais comuns  
- Nuvens de palavras (pos/neg)

---

## ğŸ§¹ 2. PrÃ©-processamento

As reviews passaram por:

- RemoÃ§Ã£o de HTML  
- RemoÃ§Ã£o de pontuaÃ§Ã£o  
- NormalizaÃ§Ã£o (lowercase)  
- RemoÃ§Ã£o de mÃºltiplos espaÃ§os  
- TokenizaÃ§Ã£o opcional  

Exemplo da funÃ§Ã£o de limpeza:

```python
def clean_text(text):
    text = remove_html(text)
    text = text.lower()
    text = re.sub(r"[^a-zA-Z\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text
```

---

## ğŸ”  3. VetorizaÃ§Ã£o TFâ€‘IDF

O texto limpo foi transformado em vetores usando:

```python
TfidfVectorizer(
    max_features=10000,
    stop_words="english",
    ngram_range=(1,1)
)
```

- 10k features â†’ captura boa variedade sem explodir dimensionalidade  
- Stopwords â†’ reduz ruÃ­do  
- Unigramas â†’ melhor desempenho para textos curtos  

---

## ğŸ¤– 4. Modelos Treinados

| Modelo | AcurÃ¡cia |
|--------|----------|
| Logistic Regression | **0.89** |
| Linear SVM | **0.89** |
| Multinomial Naive Bayes | 0.85 |

A escolha final foi entre **Logistic Regression** ou **SVM**, ambos com desempenho similar.

---

## ğŸ” 5. InterpretaÃ§Ã£o das Features

A partir dos coeficientes da RegressÃ£o LogÃ­stica, foram extraÃ­das as palavras:

- **Mais associadas a reviews positivos**  
- **Mais associadas a reviews negativos**

Esse tipo de interpretaÃ§Ã£o Ã© essencial em projetos reais para explicar decisÃµes do modelo.

---

## ğŸ“¦ 6. Como Executar

### 1 â€” Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

### 2 â€” Execute o notebook:

```bash
jupyter notebook notebooks/analise_sentimento.ipynb
```

---

## ğŸš€ 7. PossÃ­veis Melhorias

- Usar embeddings (Word2Vec, FastText, BERT)  
- Criar API com FastAPI para servir o modelo  
- Criar dashboard com Streamlit  
- Fine-tuning de modelos Transformers  

---

## ğŸ§‘â€ğŸ’» Autor

**Renan Croffi**  
Projeto desenvolvido para portfÃ³lio de CiÃªncia de Dados.  

---

## ğŸ“ LicenÃ§a  
Este projeto estÃ¡ sob a licenÃ§a MIT.
